// Code generated by genny. DO NOT EDIT.
// This file was automatically generated by genny.
// Any changes will be lost if this file is regenerated.
// see https://github.com/mauricelam/genny

package writer

import "github.com/signalfx/golib/trace"
import "github.com/signalfx/golib/datapoint"

import (
	"context"
	"log"
	"sync/atomic"
)

// DatapointPreprocessor is used to filter out or otherwise change datapoints
// before being sent.  If the return value is false, the datapoint won't be
// sent.
type DatapointPreprocessor func(*datapoint.Datapoint) bool

// DatapointSender is what sends a slice of datapoints.  It should block until
// the datapoints have been sent, or an error has occurred.
type DatapointSender func(context.Context, []*datapoint.Datapoint) error

// DatapointRingWriter is an abstraction that accepts a bunch of datapoints,
// buffers them in a ring buffer and sends them out in batches.
type DatapointRingWriter struct {
	inputChan chan *datapoint.Datapoint

	preprocessFunc DatapointPreprocessor
	sendFunc       DatapointSender

	MaxBuffered  int
	MaxRequests  int
	MaxBatchSize int

	requestsActive  int64
	requestsWaiting int64
	totalWaiting    int64

	totalReceived           int64
	totalFilteredOut        int64
	totalInFlight           int64
	totalSent               int64
	totalPotentiallyDropped int64
}

// NewDatapointRingWriter returns an initialized but not running datapoint of the
// DatapointRingWriter. You must call Run on the returned datapoint for it to work.
func NewDatapointRingWriter(preprocessFunc DatapointPreprocessor, sendFunc DatapointSender) *DatapointRingWriter {
	return &DatapointRingWriter{
		inputChan:      make(chan *datapoint.Datapoint),
		preprocessFunc: preprocessFunc,
		sendFunc:       sendFunc,

		MaxBuffered:  10000,
		MaxRequests:  10,
		MaxBatchSize: 1000,
	}
}

// InputChan returns the channel that should be used to send datapoints to this
// writer.
func (w *DatapointRingWriter) InputChan() chan *datapoint.Datapoint {
	return w.inputChan
}

// Run waits for things to come in on the provided
// channels and forwards them to SignalFx.  This function blocks until the
// provided context is finished.
func (w *DatapointRingWriter) Run(ctx context.Context) {
	bufferSize := w.MaxBuffered
	// Ring buffer of datapoints, initialized to its maximum length to avoid
	// reallocations.
	buffer := make([]*datapoint.Datapoint, bufferSize)
	// The index that marks the end of the last chunk of datapoints that was
	// sent.  It is one greater than the actual index, to match the golang
	// slice high range.
	lastHighStarted := 0
	// The next index within the buffer that a datapoint should be added to.
	nextDatapointIdx := 0
	// Corresponds to nextDatapointIdx but is easier to work with without modulo
	batched := 0
	requestDoneCh := make(chan struct{}, w.MaxRequests)

	// How many times around the ring buffer we have gone when putting
	// datapoints onto the buffer
	bufferedCircuits := int64(0)
	// How many times around the ring buffer we have gone when starting
	// requests
	startedCircuits := int64(0)

	targetHighStarted := func() int {
		if nextDatapointIdx < lastHighStarted {
			// Wrap around happened, just take what we have left until wrap
			// around so that we can take a single slice of it since slice
			// ranges can't wrap around.
			return bufferSize
		}

		return nextDatapointIdx
	}

	tryToSendBufferChunk := func(newHigh int) bool {
		if newHigh == lastHighStarted { // Nothing added
			return false
		}

		if w.requestsActive >= int64(w.MaxRequests) {
			w.requestsWaiting++
			w.totalWaiting += int64(newHigh - lastHighStarted)
			return false
		}

		w.requestsActive++
		go func(low, high int) {
			count := int64(high - low)
			atomic.AddInt64(&w.totalInFlight, count)

			w.sendFunc(ctx, buffer[low:high])

			atomic.AddInt64(&w.totalInFlight, -count)
			atomic.AddInt64(&w.totalSent, count)

			requestDoneCh <- struct{}{}
		}(lastHighStarted, newHigh)

		lastHighStarted = newHigh
		if lastHighStarted == bufferSize { // Wrap back to 0
			lastHighStarted = 0
			startedCircuits++
		}

		batched = 0
		w.requestsWaiting = 0
		w.totalWaiting = 0
		return true
	}

	handleRequestDone := func() {
		w.requestsActive--
		if w.requestsWaiting > 0 {
			tryToSendBufferChunk(targetHighStarted())
		}
	}

	process := func(inst *datapoint.Datapoint) {
		w.totalReceived++

		if w.preprocessFunc != nil && !w.preprocessFunc(inst) {
			w.totalFilteredOut++
			return
		}

		buffer[nextDatapointIdx] = inst

		nextDatapointIdx++
		if nextDatapointIdx == bufferSize { // Wrap around the buffer
			nextDatapointIdx = 0
			bufferedCircuits++
		}

		if lastHighStarted < nextDatapointIdx && bufferedCircuits > startedCircuits {
			w.totalPotentiallyDropped = int64(bufferSize)*(bufferedCircuits-startedCircuits) + int64(nextDatapointIdx-lastHighStarted)
			log.Printf("SignalFx writer: ring buffer overflowed, some instances were dropped. Set MaxBuffered to something higher (currently %d)", bufferSize)
		}
		batched++

		if batched >= w.MaxBatchSize {
			tryToSendBufferChunk(targetHighStarted())
		}
	}

	for {
		select {
		case <-ctx.Done():
			return

		case inst := <-w.inputChan:
			process(inst)

		case <-requestDoneCh:
			handleRequestDone()

		default:
			newHigh := targetHighStarted()
			// Could be less if wrapped around
			if newHigh != lastHighStarted {
				tryToSendBufferChunk(newHigh)
			}

			select {
			case <-ctx.Done():
				return

			case <-requestDoneCh:
				handleRequestDone()

			case inst := <-w.inputChan:
				process(inst)
			}
		}
	}
}

// SpanPreprocessor is used to filter out or otherwise change spans
// before being sent.  If the return value is false, the span won't be
// sent.
type SpanPreprocessor func(*trace.Span) bool

// SpanSender is what sends a slice of spans.  It should block until
// the spans have been sent, or an error has occurred.
type SpanSender func(context.Context, []*trace.Span) error

// SpanRingWriter is an abstraction that accepts a bunch of spans,
// buffers them in a ring buffer and sends them out in batches.
type SpanRingWriter struct {
	inputChan chan *trace.Span

	preprocessFunc SpanPreprocessor
	sendFunc       SpanSender

	MaxBuffered  int
	MaxRequests  int
	MaxBatchSize int

	requestsActive  int64
	requestsWaiting int64
	totalWaiting    int64

	totalReceived           int64
	totalFilteredOut        int64
	totalInFlight           int64
	totalSent               int64
	totalPotentiallyDropped int64
}

// NewSpanRingWriter returns an initialized but not running span of the
// SpanRingWriter. You must call Run on the returned span for it to work.
func NewSpanRingWriter(preprocessFunc SpanPreprocessor, sendFunc SpanSender) *SpanRingWriter {
	return &SpanRingWriter{
		inputChan:      make(chan *trace.Span),
		preprocessFunc: preprocessFunc,
		sendFunc:       sendFunc,

		MaxBuffered:  10000,
		MaxRequests:  10,
		MaxBatchSize: 1000,
	}
}

// InputChan returns the channel that should be used to send spans to this
// writer.
func (w *SpanRingWriter) InputChan() chan *trace.Span {
	return w.inputChan
}

// Run waits for things to come in on the provided
// channels and forwards them to SignalFx.  This function blocks until the
// provided context is finished.
func (w *SpanRingWriter) Run(ctx context.Context) {
	bufferSize := w.MaxBuffered
	// Ring buffer of datapoints, initialized to its maximum length to avoid
	// reallocations.
	buffer := make([]*trace.Span, bufferSize)
	// The index that marks the end of the last chunk of datapoints that was
	// sent.  It is one greater than the actual index, to match the golang
	// slice high range.
	lastHighStarted := 0
	// The next index within the buffer that a datapoint should be added to.
	nextDatapointIdx := 0
	// Corresponds to nextDatapointIdx but is easier to work with without modulo
	batched := 0
	requestDoneCh := make(chan struct{}, w.MaxRequests)

	// How many times around the ring buffer we have gone when putting
	// datapoints onto the buffer
	bufferedCircuits := int64(0)
	// How many times around the ring buffer we have gone when starting
	// requests
	startedCircuits := int64(0)

	targetHighStarted := func() int {
		if nextDatapointIdx < lastHighStarted {
			// Wrap around happened, just take what we have left until wrap
			// around so that we can take a single slice of it since slice
			// ranges can't wrap around.
			return bufferSize
		}

		return nextDatapointIdx
	}

	tryToSendBufferChunk := func(newHigh int) bool {
		if newHigh == lastHighStarted { // Nothing added
			return false
		}

		if w.requestsActive >= int64(w.MaxRequests) {
			w.requestsWaiting++
			w.totalWaiting += int64(newHigh - lastHighStarted)
			return false
		}

		w.requestsActive++
		go func(low, high int) {
			count := int64(high - low)
			atomic.AddInt64(&w.totalInFlight, count)

			w.sendFunc(ctx, buffer[low:high])

			atomic.AddInt64(&w.totalInFlight, -count)
			atomic.AddInt64(&w.totalSent, count)

			requestDoneCh <- struct{}{}
		}(lastHighStarted, newHigh)

		lastHighStarted = newHigh
		if lastHighStarted == bufferSize { // Wrap back to 0
			lastHighStarted = 0
			startedCircuits++
		}

		batched = 0
		w.requestsWaiting = 0
		w.totalWaiting = 0
		return true
	}

	handleRequestDone := func() {
		w.requestsActive--
		if w.requestsWaiting > 0 {
			tryToSendBufferChunk(targetHighStarted())
		}
	}

	process := func(inst *trace.Span) {
		w.totalReceived++

		if w.preprocessFunc != nil && !w.preprocessFunc(inst) {
			w.totalFilteredOut++
			return
		}

		buffer[nextDatapointIdx] = inst

		nextDatapointIdx++
		if nextDatapointIdx == bufferSize { // Wrap around the buffer
			nextDatapointIdx = 0
			bufferedCircuits++
		}

		if lastHighStarted < nextDatapointIdx && bufferedCircuits > startedCircuits {
			w.totalPotentiallyDropped = int64(bufferSize)*(bufferedCircuits-startedCircuits) + int64(nextDatapointIdx-lastHighStarted)
			log.Printf("SignalFx writer: ring buffer overflowed, some instances were dropped. Set MaxBuffered to something higher (currently %d)", bufferSize)
		}
		batched++

		if batched >= w.MaxBatchSize {
			tryToSendBufferChunk(targetHighStarted())
		}
	}

	for {
		select {
		case <-ctx.Done():
			return

		case inst := <-w.inputChan:
			process(inst)

		case <-requestDoneCh:
			handleRequestDone()

		default:
			newHigh := targetHighStarted()
			// Could be less if wrapped around
			if newHigh != lastHighStarted {
				tryToSendBufferChunk(newHigh)
			}

			select {
			case <-ctx.Done():
				return

			case <-requestDoneCh:
				handleRequestDone()

			case inst := <-w.inputChan:
				process(inst)
			}
		}
	}
}
